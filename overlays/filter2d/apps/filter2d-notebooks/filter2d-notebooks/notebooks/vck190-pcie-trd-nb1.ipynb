{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Xilinx Logo](images/xilinx_logo.png \"Xilinx Logo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to configure a V4L2 device or video raw file from host machine through pcie, processes media content through 2D filter(optional) and transfers processed content to host via PCIe (or) display the content on hdmi monitor.\n",
    "\n",
    "Depending on the usecase following Gstreamer elements are used:\n",
    "* The `appsrc` element defined in xlnx_pcie_abstract python module is used to receive video frames from host       machine.\n",
    "* The `vvas_xfilter` element is used to implement a 2D convolution filter.\n",
    "* The `appsink` element defined in xlnx_pcie_abstract python module is used to send video frames to host mahine   in zero copy fashion.\n",
    "* The `kmsink` elemenet is used to display video frames on the hdmi monitor.\n",
    "\n",
    "Three different use cases are demonstrated using gstreamer based pcie Endpoint application.\n",
    "* Capture from v4l2 device (MIPI), process the video frames using vvas_xfilter plugin (or) bypass the vvas_xfilter   plugin and display on host machine using appsink.\n",
    "\n",
    "* Receive a video file from host machine using appsrc, process the received frames using vvas_xfilter plugin (or)   bypass vvas_xfilter plugin and send processed video frames to host machine through appsink.\n",
    "\n",
    "* Receive a video file from host machine using appsrc,process the received frames using vvas_xfilter plugin (or)   bypass vvas_xfilter plugin and display processed video frames on kmssink (HDMI)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Imports and Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all python modules required for this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display, clear_output\n",
    "from threading import Thread\n",
    "\n",
    "import sys, time, gi\n",
    "gi.require_version('Gst', '1.0')\n",
    "gi.require_version(\"GstApp\", \"1.0\")\n",
    "from gi.repository import GObject, GLib, Gst, GstApp\n",
    "\n",
    "# Importing enum for enumerations of usecases \n",
    "import enum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the VCK190-PCIe TRD notebook 3 (nb3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = \"nb3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing xlnx_pcie_abstract python module \n",
    "\n",
    "* xlnx_pcie_abstract python module is an abstraction which is used to create required `appsrc` and `appsink` elements, also helps to move media content between `src` --> with/bypass `vvas_xfilter` --> `sink` elements. \n",
    "\n",
    "* To move  media content between elements following wrapper functions are implement and are bind through Glib connect call. \n",
    "    - `need_data` callback is used to push data read from pcie to next elements i.e., `vvas_xfilter` (or) `appsink` (or) `kmssink` based on the control parameters received from host machine.\n",
    "    - `new_sample_cb` callback is used to pull data from `appsrc` (or) `vvas_xfilter` based on the control parameters received from host machine and pass the media content to appsink via pcie . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing xlnx_pcie_abstract python module\n",
    "import xlnx_pcie_abstract\n",
    "import ctypes\n",
    "from ctypes import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different usecases are defined though enumeration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Usecase(enum.IntEnum):\n",
    "    VGST_USECASE_TYPE_NONE = 0\n",
    "    VGST_USECASE_TYPE_MIPISRC_FLTR_HOST = 1\n",
    "    VGST_USECASE_TYPE_MIPISRC_TO_HOST = 3\n",
    "    VGST_USECASE_TYPE_APPSRC_FLTR_HOST = 4\n",
    "    VGST_USECASE_TYPE_APPSRC_TO_HOST = 5\n",
    "    VGST_USECASE_TYPE_APPSRC_FLTR_KMSSINK = 6\n",
    "    VGST_USECASE_TYPE_APPSRC_TO_KMSSINK = 8\n",
    "    VGST_USECASE_TYPE_MAX = 9\n",
    "\n",
    "pcie_fd = xlnx_pcie_abstract.PCIe_GetDevice()\n",
    "\n",
    "usecase = xlnx_pcie_abstract.PCIe_Getusecase(pcie_fd)\n",
    "if( (usecase.value <= Usecase.VGST_USECASE_TYPE_NONE)  and (usecase.value >= Usecase.VGST_USECASE_TYPE_NONE) ) :\n",
    "    raise Exception(\"Unsupported usecases\" )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create Src , Filter, and Sink elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the ``mediasrcbin`` element which is a bin element that uses the standard ``v4l2src`` element inside. Set the following some properties:\n",
    "* Set the ``media-device`` property to the desired media device node\n",
    "* Register the above ``pad_added`` callback function with the ``pad-added`` signal of the ``mediasrcbin`` element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_added(element, pad):\n",
    "    sink_pad = caps.get_static_pad(\"sink\")\n",
    "    if not sink_pad.is_linked():\n",
    "        pad.link(sink_pad)\n",
    "        if src_type == \"mipi\" :\n",
    "            pad.set_property(\"io-mode\", \"dmabuf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `mediasrcbin` or `appsrc` element based on the control information received from host machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gst.init(None)\n",
    "if ( usecase.value <= Usecase.VGST_USECASE_TYPE_MIPISRC_TO_HOST) :\n",
    "        src_type = \"mipi\"\n",
    "        device = xlnx_pcie_abstract.get_device_by_name(src_type)\n",
    "        if device is None:\n",
    "            raise Exception('Unable to find video source ' + src_type + '. Make sure the device is plugged in, powered, and the correct platform is used.')\n",
    "        src = Gst.ElementFactory.make(\"mediasrcbin\")\n",
    "        src.set_property(\"media-device\", device)\n",
    "        src.connect(\"pad_added\", pad_added);   \n",
    "        \n",
    "        res_dict = {\n",
    "            \"1080p\" : (\"1920\", \"1080\"),\n",
    "            \"2160p\" : (\"3840\", \"2160\")\n",
    "            }\n",
    "\n",
    "        resp = xlnx_pcie_abstract.PCIe_GetResolution(pcie_fd)        \n",
    "        if(resp == 2160) :\n",
    "            res = \"2160p\" # Change the resolution string to 720p, 1080p, or 2160p (mipi only)\n",
    "            !xmediactl.sh\n",
    "        else :\n",
    "            res = \"1080p\"\n",
    "            !xmediactl_1080.sh\n",
    "        width = res_dict[res][0]\n",
    "        height = res_dict[res][1]\n",
    "        #print(\"Selected resolution: \" + width + \"x\" + height)\n",
    "        fmt = \"YUY2\"\n",
    "        caps = Gst.ElementFactory.make(\"capsfilter\")\n",
    "        cap = Gst.Caps.from_string(\"video/x-raw, width=\" + str(width) + \", height=\" + str(height) + \", format=\" + fmt)\n",
    "        caps.set_property(\"caps\", cap)\n",
    "\n",
    "elif (usecase.value >= Usecase.VGST_USECASE_TYPE_APPSRC_FLTR_HOST)  :\n",
    "        src = Gst.ElementFactory.make(\"appsrc\")\n",
    "        caps = Gst.ElementFactory.make(\"capsfilter\")\n",
    "        xlnx_pcie_abstract.xlnx_pcieappsrc(src,caps)\n",
    "        xlnx_pcie_abstract.export_pciedmabuff(pcie_fd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `appsink` or `kmssink` element based on the control information received from host machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (usecase.value < Usecase.VGST_USECASE_TYPE_APPSRC_FLTR_KMSSINK) :\n",
    "        sink = Gst.ElementFactory.make(\"appsink\")\n",
    "        xlnx_pcie_abstract.xlnx_pcieappsink(sink)\n",
    "\n",
    "elif (usecase.value >= Usecase.VGST_USECASE_TYPE_APPSRC_FLTR_KMSSINK )   :\n",
    "        #print(\"kmssink use case\")\n",
    "        driver_name = \"xlnx\"\n",
    "        plane_id = 38\n",
    "        xoff = 0 # Change this value to move the plane position in the x-direction\n",
    "        yoff = 0 # Change this value to move the plane position in the y-direction\n",
    "        width = int('3840', 10)\n",
    "        height = int('2160', 10)\n",
    "        render_rectangle = Gst.ValueArray((xoff, yoff, width, height))\n",
    "        hdmisink = Gst.ElementFactory.make(\"kmssink\")\n",
    "        hdmisink.set_property(\"driver-name\", driver_name)\n",
    "        hdmisink.set_property(\"plane-id\", plane_id)\n",
    "        hdmisink.set_property(\"render-rectangle\", render_rectangle)\n",
    "        hdmisink.set_property(\"sync\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create vvas_xfilter element based on the control information received from host machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_filter = '0'\n",
    "if ( (usecase.value != Usecase.VGST_USECASE_TYPE_MIPISRC_TO_HOST ) and\n",
    "        (usecase.value != Usecase.VGST_USECASE_TYPE_APPSRC_TO_HOST ) and \n",
    "            (usecase.value != Usecase.VGST_USECASE_TYPE_APPSRC_TO_KMSSINK ) ) :\n",
    "    add_filter = '1'\n",
    "    \n",
    "    jsondir = \"/usr/share/vvas/vck190-pcie-trd/\"\n",
    "    jfile = jsondir + \"kernel_xfilter2d_pl.json\"\n",
    "\n",
    "    filter2d = Gst.ElementFactory.make(\"vvas_xfilter\")\n",
    "    filter2d.set_property(\"kernels-config\", jfile)\n",
    "    plist = [\n",
    "        \"blur\",\n",
    "        \"edge\",\n",
    "        \"horizontal edge\",\n",
    "        \"vertical edge\",\n",
    "        \"emboss\",\n",
    "        \"horizontal gradient\",\n",
    "        \"vertical gradient\",\n",
    "        \"identity\",\n",
    "        \"sharpen\",\n",
    "        \"horizontal sobel\",\n",
    "        \"vertical sobel\",\n",
    "        \"custom\"\n",
    "        ]\n",
    "\n",
    "    def print_presets():\n",
    "        print(\"Supported filter presets:\\n\")\n",
    "        print('\\n'.join(plist) + '\\n')\n",
    "    \n",
    "    #print_presets()\n",
    "    def set_preset(val) :\n",
    "        if val in plist :\n",
    "            jstring = '{ \"filter_preset\" : \"' +  val + '\" }'\n",
    "            filter2d.set_property(\"dynamic-config\", jstring)\n",
    "        else :\n",
    "            raise Exception(\"Unsupported filter preset \\'\" + val + \"\\'\")\n",
    "\n",
    "    filter_preset = xlnx_pcie_abstract.PCIe_GetFilterPreset(pcie_fd)        \n",
    "    set_preset(plist[filter_preset.value])\n",
    "\n",
    "    def set_coeff(val):\n",
    "        jstring = '{ \"filter_coefficients\" : ' + val + ' }'\n",
    "        filter2d.set_property(\"dynamic-config\", jstring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the ``perf`` element which is used to measure and print the frame rate while the video pipeline is running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf = Gst.ElementFactory.make(\"perf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create and Run the GStreamer Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the pipeline, add all elements, and link them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Gst.Pipeline.new(nb)\n",
    "pipeline.add(src)\n",
    "if (usecase.value <= Usecase.VGST_USECASE_TYPE_MIPISRC_TO_HOST ) :\n",
    "    pipeline.add(caps)\n",
    "    if(add_filter == '1') :\n",
    "         pipeline.add(filter2d)\n",
    "    pipeline.add(perf)\n",
    "    pipeline.add(sink)\n",
    "    \n",
    "    src.link(caps)\n",
    "    if(add_filter == '1') :\n",
    "        caps.link(filter2d)\n",
    "        filter2d.link(perf)\n",
    "        perf.link(sink)\n",
    "    else :\n",
    "        caps.link(perf)\n",
    "        perf.link(sink)\n",
    "        \n",
    "\n",
    "if ( (usecase.value > Usecase.VGST_USECASE_TYPE_MIPISRC_TO_HOST) and\n",
    "         (usecase.value <= Usecase.VGST_USECASE_TYPE_APPSRC_TO_HOST) )   :\n",
    "    if(add_filter == '1') :\n",
    "         pipeline.add(filter2d)\n",
    "    pipeline.add(perf)\n",
    "    pipeline.add(sink)\n",
    "    \n",
    "    if(add_filter == '1') :\n",
    "        src.link(filter2d)\n",
    "        filter2d.link(perf)\n",
    "        perf.link(sink)\n",
    "    else :\n",
    "        src.link(perf)\n",
    "        perf.link(sink)\n",
    "\n",
    "if (usecase.value >= Usecase.VGST_USECASE_TYPE_APPSRC_FLTR_KMSSINK) :\n",
    "    if(add_filter == '1') :\n",
    "         pipeline.add(filter2d)\n",
    "    pipeline.add(perf)\n",
    "    pipeline.add(hdmisink)\n",
    "    \n",
    "    if(add_filter == '1') :\n",
    "        src.link(filter2d)\n",
    "        filter2d.link(perf)\n",
    "        perf.link(hdmisink)\n",
    "    else :\n",
    "        src.link(perf)\n",
    "        perf.link(hdmisink)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the pipeline (set to `PLAYING` state), create the main loop and listen to messages on the bus. Register the `bus_call` callback function with the `message` signal of the bus. Start the main loop.\n",
    "\n",
    "The video will be displayed on the monitor. The frame rate will be printed and updated below the code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bus_call(bus, message, loop):\n",
    "    t = message.type\n",
    "    if t == Gst.MessageType.EOS:\n",
    "        sys.stdout.write(\"End-of-stream\\n\")\n",
    "        xlnx_pcie_abstract.xlnx_pciecleanup()\n",
    "        pipeline.set_state(Gst.State.NULL)\n",
    "        Gst.deinit()\n",
    "        loop.quit()\n",
    "    elif t == Gst.MessageType.INFO:\n",
    "        err, info = message.parse_info()\n",
    "        sys.stderr.write(\"Info: %s\\n\" % info)\n",
    "        clear_output(wait=True)\n",
    "    elif t == Gst.MessageType.ERROR:\n",
    "        err, debug = message.parse_error()\n",
    "        sys.stderr.write(\"Error: %s: %s\\n\" % (err, debug))\n",
    "        pipeline.set_state(Gst.State.NULL)\n",
    "        loop.quit()\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit_pipeline = 0\n",
    "if(usecase.value <= Usecase.VGST_USECASE_TYPE_MIPISRC_TO_HOST) :\n",
    "    def thread_eos_status(threadname) :\n",
    "        global src\n",
    "        global exit_pipeline\n",
    "        while(exit_pipeline != 1) :\n",
    "            stop_feed = xlnx_pcie_abstract.stop_mipi_feed() \n",
    "            if (stop_feed) :\n",
    "                src.send_event(Gst.Event.new_eos())\n",
    "                xlnx_pcie_abstract.xlnx_pciecleanup()\n",
    "    \n",
    "    check_eos_thread = Thread(target=thread_eos_status, args=(\"thread_eos_status\",))\n",
    "\n",
    "pipeline.set_state(Gst.State.PLAYING);\n",
    "loop = GLib.MainLoop()\n",
    "bus = pipeline.get_bus()\n",
    "bus.add_signal_watch()\n",
    "bus.connect(\"message\",bus_call, loop)\n",
    "if(usecase.value <= Usecase.VGST_USECASE_TYPE_MIPISRC_TO_HOST) :\n",
    "    check_eos_thread.start()\n",
    "    \n",
    "try:\n",
    "    loop.run()\n",
    "except:\n",
    "    if (usecase.value <= Usecase.VGST_USECASE_TYPE_MIPISRC_TO_HOST) :\n",
    "            xlnx_pcie_abstract.xlnx_pciecleanup()\n",
    "    sys.stdout.write(\"Interrupt caught\\n\")\n",
    "    pipeline.set_state(Gst.State.NULL)\n",
    "    loop.quit()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Copyright© 2023 AMD</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
