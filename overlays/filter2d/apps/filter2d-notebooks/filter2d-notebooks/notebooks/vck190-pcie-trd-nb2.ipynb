{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Xilinx Logo](images/xilinx_logo.png \"Xilinx Logo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to capture video from a MIPI device, processes it through 2D convolution filter accelerator  and display the output on a monitor using a DRM/KMS display device. This notebook uses the GStreamer multimedia framework. In addition, the memory bandwidth is measured and plotted in a parallel notebook.\n",
    "\n",
    "The display device uses the Xilinx DRM/KMS driver. A video mixer supports alpha blending of multiple layers (also called planes). \n",
    "The plane formats are fixed and configured as follows:\n",
    "* 4 BG24 planes (IDs: 34-37)\n",
    "* 4 YUY2 planes (IDs: 38-41)\n",
    "* 1 ARGB plane (ID: 42) - this is the primary plane used for setting the CRTC resolution\n",
    "\n",
    "The video mixer is connected to an HDMI encoder which drives the display. Both video mixer and HDMI encoder are implemented inside the FPGA.\n",
    "\n",
    "The 2D filter has a fixed kernel size of 3x3. It operates on the luma channel of a YUY2 image; The PL 2D filter performs the chroma loopback inside the kernel itself. In addition, the PL version has run-time programmable kernel coefficients and presets as well as well image dimensions.\n",
    "\n",
    "For more information on the 2D convolution filter operation, see here: https://en.wikipedia.org/wiki/Kernel_(image_processing).\n",
    "\n",
    "The various 2D filter accelerators are integrated into Gstreamer using the Vitis Video Analytics SDK (VVAS) which provides a set of plugins and an abstraction layer on top of the Xilinx run-time (XRT). For more information, see here: https://xilinx.github.io/VVAS/.\n",
    "\n",
    "2D filter is implemented in the PL using the Vitis Vision libraries and high-level synthesis (HLS)\n",
    "\n",
    "The video pipeline is composed of the following GStreamer elements:\n",
    "* The ``mediasrcbin`` element is used to capture video from a V4L2 device. It is a bin element on top of the standard ``v4l2src`` element which performs additional media pipeline initialization (if needed).\n",
    "* The ``vvas_xfilter`` element is used to implement a 2D convolution filter\n",
    "* The ``perf`` element is used to measure and print the frame rate\n",
    "* The ``kmssink`` element is used to display video on a monitor using the DRM/KMS kernel subsystem\n",
    "\n",
    "The ``vck190-pcie-trd-apm`` notebook is executed in parallel to this notebook to measure and plot the memory bandwidth of the live video pipeline.\n",
    "\n",
    "In this notebook, you will:\n",
    "1. Create a GStreamer video pipeline that captures video from a V4L2 device and displays the video on a monitor using DRM/KMS.\n",
    "2. The vvas_xfilter element is used to wrap the 2D convolution filter accelerator library (Optional)\n",
    "3. Gstreamer pipeline with and without filter is created using the configuration parameter.\n",
    "4. Run the ``trd-apm`` notebook to measure and plot the memory bandwidth while the video pipeline is running.\n",
    "5. Create a GStreamer pipeline graph and view it inside this notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Imports and Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all python modules required for this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display, clear_output\n",
    "import pydot\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "import gi\n",
    "import os\n",
    "import glob\n",
    "gi.require_version('Gst', '1.0')\n",
    "gi.require_version(\"GstApp\", \"1.0\")\n",
    "from gi.repository import GObject, GLib, Gst, GstApp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the VCK190-PCIe TRD notebook 2 (nb2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = \"nb2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a directory for saving the pipeline graph as dot file. Set the GStreamer debug dot directory environement variable to point to that directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotdir = \"/home/root/gst-dot/\" + nb\n",
    "!mkdir -p $dotdir\n",
    "%env GST_DEBUG_DUMP_DOT_DIR = $dotdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the GStreamer library. Optionally enable debug (default off) and set the debug level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gst.init(None)\n",
    "Gst.debug_set_active(False)\n",
    "Gst.debug_set_threshold_from_string('*:1', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Run the APM Notebook to Plot the Memory Bandwidth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the ``vck190-pcie-trd-apm.ipynb`` notebook from the *File Browser* in a new tab. Execute the notebook by selecting *Run -> Run All Cells* from the Jupyter Lab menu bar. In section 4 of the APM notebook, a horizontal bar graph is shown that plots the currently consumed memory bandwidth split out by different AXI ports. For more information, read the APM notebook tutorial.\n",
    "\n",
    "Once you see the graph, right-click the graph and select *Create New View for Output*. This will create a new window/tab with just the graph. Now re-arrange the window by dragging it to the the right side of the screen so it shows side-by-side with the notebook window (see screenshot below).\n",
    "\n",
    "![APM Plot](images/apm-plot-nb3.jpg \"APM Plot\")\n",
    "\n",
    "Switch tabs back to the nb2 notebook and follow the steps below. Once the video pipeline is running, you will notice the bar graph will be updated live with the measured memory bandwidth numbers in Gbps.\n",
    "\n",
    "**Note:** You can keep the memory bandwith output view open while switching between notebooks. There is no need to restart the APM notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate the correct Vitis Overlay is available in the platform for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"0000:00:00.0\"\n",
    "def xbutil_program_xclbin():\n",
    "    xclbin = \"/boot/binary_container_1.xclbin\"\n",
    "    if os.path.exists(xclbin):\n",
    "        subprocess.run(['xbutil', 'program', '-d', device, '-u', xclbin], check=True)\n",
    "\n",
    "def xbutil_query_cu(cu):\n",
    "    proc = subprocess.run(['xbutil', 'examine', '-d', device], capture_output=True, encoding='utf8')\n",
    "    for line in proc.stdout.splitlines():\n",
    "        if cu in line:\n",
    "            return\n",
    "    raise Exception(\"Unable to find compute unit \\'\" + cu + \"\\'. Make sure the correct Vitis overlay is used.\")\n",
    "\n",
    "xbutil_program_xclbin()\n",
    "xbutil_query_cu(\"filter2d_pl_accel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create and Configure the GStreamer Elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The get_media_by_device function returns the matching media node for a given video capture source. The following sources are supported in this notebook:\n",
    "* ``mipi`` : platform1 only, requires FMC card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device_by_name(src):\n",
    "    sources = {\n",
    "        'mipi' : 'vcap_csi',\n",
    "    }\n",
    "    \n",
    "    devices = glob.glob('/dev/media*')\n",
    "    for dev in devices:\n",
    "        proc = subprocess.run(['media-ctl', '-d', dev, '-p'], capture_output=True, encoding='utf8')\n",
    "        for line in proc.stdout.splitlines():\n",
    "            if sources[src] in line:\n",
    "                return dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the ``source`` based on available media devices for this platform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_type = \"mipi\"\n",
    "device = get_device_by_name(src_type) \n",
    "if device is None:\n",
    "    raise Exception('Unable to find video source ' + src_type + '. Make sure the device is plugged in, powered, and the correct platform is used.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source pads of the ``mediasrcbin`` element are created dynamically when it detects the incoming stream. The ``pad-added`` signal is emitted and this ``pad_added`` callback function is executed. It links the source pads of the mediasrcbin elements to the sink pads of the ``caps`` elements.\n",
    "\n",
    "Set the ``io-mode`` on the pad which propagates to the ``v4l2src`` node. If MIPI is selected, set the I/O mode to DMABUF (https://www.kernel.org/doc/html/v4.16/driver-api/dma-buf.html) which allows sharing of video buffers in 0-copy fashion between the source and sink elements. Otherwise, set the I/O mode to mmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_added(element, pad):\n",
    "    sink_pad = caps.get_static_pad(\"sink\")\n",
    "    if not sink_pad.is_linked():\n",
    "        pad.link(sink_pad)\n",
    "        if src_type == \"mipi\" :\n",
    "            pad.set_property(\"io-mode\", \"dmabuf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the ``mediasrcbin`` element which is a bin element that uses the standard ``v4l2src`` element inside. Set the following some properties:\n",
    "* Set the ``media-device`` property to the desired media device node\n",
    "* Register the above ``pad_added`` callback function with the ``pad-added`` signal of the ``mediasrcbin`` element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = Gst.ElementFactory.make(\"mediasrcbin\")\n",
    "src.set_property(\"media-device\", device)\n",
    "src.connect(\"pad_added\", pad_added);    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a caps filter element to set the desired resolution (width and height) and format. The caps filter is configured to parse the mentioned properties from a string.\n",
    "\n",
    "``mipi`` as source type, the maximum supported resolution is 3840x2160 (4K) at 60 fps. Note that the connected monitor also needs to support this resolution, otherwise the pipeline will fail during caps negotiation (see modeprint output below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict = {\n",
    "    \"720p\" : (\"1280\", \"720\"),\n",
    "    \"1080p\" : (\"1920\", \"1080\"),\n",
    "    \"2160p\" : (\"3840\", \"2160\")\n",
    "}\n",
    "res = \"2160p\" # Change the resolution string to 720p, 1080p, or 2160p (mipi only)\n",
    "width = res_dict[res][0]\n",
    "height = res_dict[res][1]\n",
    "print(\"Selected resolution: \" + width + \"x\" + height)\n",
    "\n",
    "fmt = \"YUY2\"\n",
    "fps = \"60/1\"\n",
    "caps = Gst.ElementFactory.make(\"capsfilter\")\n",
    "cap = Gst.Caps.from_string(\"video/x-raw, width=\" + str(width) + \", height=\" + str(height) + \", format=\" + fmt + \", framerate=\" + fps)\n",
    "caps.set_property(\"caps\", cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_filter = '0' # By default pipeline is created without filter, change this variable to 1 to add filter."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Create the vvas_xfilter element. \n",
    "\n",
    "The ``kernels-config`` property is set to a json file path which contains configuration paramaters of the 2D filter implementation to be loaded at initialization time.\n",
    "The ``dynamic-config`` property accepts a json string that is passed to the kernel each time when the start function is called. \n",
    "This allows kernel parameters to be updated dynamically while the pipeline is running.\n",
    "The json file captures the following filter2d specific configuration paramaters:\n",
    "\n",
    "debug_level : level for debug messages of this kernel library\n",
    "in_fourcc : input format in fourcc notation; this TRD support 'YUY2' only\n",
    "out_fourcc : output format in fourcc notation; this TRD supports 'YUY2' only\n",
    "filter_preset : filter preset name that translates to a set of coefficients\n",
    "filter_coefficients : 3x3 matrix of kernel coefficients; valid only if filter_preset is set to 'custom'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if add_filter == '1':\n",
    "    jsondir = \"/usr/share/vvas/vck190-pcie-trd/\"\n",
    "    filter_kernels = [\"PL\", \"SW\"]\n",
    "    filter_kernel = filter_kernels[0] # To change filter kernel to either PL or SW\n",
    "    print(\"Selected filter2d kernel: \" + filter_kernel)\n",
    "    if filter_kernel == \"PL\":\n",
    "        jfile = jsondir + \"kernel_xfilter2d_pl.json\"\n",
    "    else: # filter_kernel == \"SW\"\n",
    "        jfile = jsondir + \"kernel_xfilter2d_sw.json\"\n",
    "\n",
    "    filter2d = Gst.ElementFactory.make(\"vvas_xfilter\")\n",
    "    filter2d.set_property(\"kernels-config\", jfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PL filter2d has two ways of programming the filter coefficients:\n",
    "\n",
    "by setting the filter_preset which translates to a set of coefficients\n",
    "by setting the filter_coefficients directly\n",
    "\n",
    "First, we look at how to set the filter_preset parameter. The below command returns a list of supported presets to choose from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if add_filter == '1':\n",
    "    plist = [\n",
    "        \"blur\",\n",
    "        \"edge\",\n",
    "        \"horizontal edge\",\n",
    "        \"vertical edge\",\n",
    "        \"emboss\",\n",
    "        \"horizontal gradient\",\n",
    "        \"vertical gradient\",\n",
    "        \"identity\",\n",
    "        \"sharpen\",\n",
    "        \"horizontal sobel\",\n",
    "        \"vertical sobel\",\n",
    "        \"custom\"\n",
    "    ]\n",
    "\n",
    "    def print_presets():\n",
    "        print(\"Supported filter presets:\\n\")\n",
    "        print('\\n'.join(plist) + '\\n')\n",
    "    \n",
    "    #print_presets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the filter_preset parameter to one of the supported values listed above e.g. \"horizontal sobel\" by passing the json string via the dynamic-config element property. The kernel library reads the preset and programs the filter coefficients behind the scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if add_filter == '1' :\n",
    "    def set_preset(val):\n",
    "        if val in plist:\n",
    "            jstring = '{ \"filter_preset\" : \"' +  val + '\" }'\n",
    "            print(jstring)\n",
    "            filter2d.set_property(\"dynamic-config\", jstring)\n",
    "        else:\n",
    "            print(\"excep\")\n",
    "            raise Exception(\"Unsupported filter preset \\'\" + val + \"\\'\")\n",
    "\n",
    "    set_preset(\"vertical gradient\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second way is to explicitly program the coefficients via the filter_coefficients parameter. Uncomment the last line in the next cell to program the coefficients via the dynamic-config element property.\n",
    "\n",
    "The filter coefficients are a 3x3 matrix of short int values. The default values in the below code snippet correspond to the identity matrix which results is a simple passthrough. The identity coefficients are as follows:\n",
    "\n",
    " 0  0  0\n",
    " 0  1  0\n",
    " 0  0  0\n",
    "To match the coefficients for \"horizontal sobel\", use the following matrix:\n",
    "\n",
    " 1  2  1\n",
    " 0  0  0\n",
    "-1 -2 -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if add_filter == '1':\n",
    "    def set_coeff(val):\n",
    "        jstring = '{ \"filter_coefficients\" : ' + val + ' }'\n",
    "        #print(jstring)\n",
    "        filter2d.set_property(\"dynamic-config\", jstring)\n",
    "\n",
    "    #set_coeff(\"[[0, 0, 0], [0, 1, 0], [0, 0, 0]]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the ``perf`` element which is used to measure and print the frame rate while the video pipeline is running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf = Gst.ElementFactory.make(\"perf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The display driver creates a DRM device node with the module name ``xlnx``.\n",
    "\n",
    "List information about the DRM device by passing the module name to the ``modeprint`` utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!modeprint xlnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the ``kmssink`` element and set some properties:\n",
    "* Set the ``driver-name`` property to the Xilinx DRM driver name ``xlnx``.\n",
    "* Set the ``plane-id`` property to the ID value of the target plane. The default value 34 is set to the first YUY2 plane.\n",
    "* Set the ``fullscreen-overlay`` property to ``False`` to keep the CRTC set to the native display resolution.\n",
    "* Set the ``render-rectangle`` property to a quadruple consisting of x-offset, y-offset, width, and height. The render-rectangle allows moving a plane position on the display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_name = \"xlnx\"\n",
    "plane_id = 38\n",
    "xoff = 0 # Change this value to move the plane position in the x-direction\n",
    "yoff = 0 # Change this value to move the plane position in the y-direction\n",
    "width = int(width, 10)\n",
    "height = int(height, 10)\n",
    "render_rectangle = Gst.ValueArray((xoff, yoff, width, height))\n",
    "\n",
    "sink = Gst.ElementFactory.make(\"kmssink\")\n",
    "sink.set_property(\"driver-name\", driver_name)\n",
    "sink.set_property(\"plane-id\", plane_id)\n",
    "sink.set_property(\"render-rectangle\", render_rectangle)\n",
    "sink.set_property(\"sync\", False)\n",
    "\n",
    "# Uncomment the below code to read back the newly set property values\n",
    "#print(\"sink properties: \")\n",
    "#print(\"driver-name: \" + str(sink.get_property(\"driver-name\")))\n",
    "#print(\"plane-id: \" + str(sink.get_property(\"plane-id\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Create and Run the GStreamer Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the pipeline, add all elements, and link them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Gst.Pipeline.new(nb)\n",
    "\n",
    "pipeline.add(src)\n",
    "pipeline.add(caps)\n",
    "pipeline.add(perf)\n",
    "if add_filter == '1':\n",
    "    pipeline.add(filter2d) # Create the filter2d element\n",
    "pipeline.add(sink)\n",
    "\n",
    "src.link(caps)\n",
    "if add_filter == '1':\n",
    "    caps.link(filter2d) # Link the fiter2d element's sink pad to the caps element \n",
    "    filter2d.link(perf)\n",
    "else:\n",
    "    caps.link(perf)\n",
    "perf.link(sink);\n",
    "print(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``bus_call`` function listens on the bus for ``EOS``, ``INFO`` and ``ERROR`` events. In case of ``EOS`` or ``ERROR``, stop the pipeline (set to ``NULL`` state) and quit the main loop. \n",
    "\n",
    "For ``INFO`` and ``ERROR`` events, parse and print the info/error message. The ``perf`` element generates ``INFO`` events with the measured frame rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bus_call(bus, message, loop):\n",
    "    t = message.type\n",
    "    if t == Gst.MessageType.EOS:\n",
    "        sys.stdout.write(\"End-of-stream\\n\")\n",
    "        pipeline.set_state(Gst.State.NULL)\n",
    "        loop.quit()\n",
    "    elif t == Gst.MessageType.INFO:\n",
    "        err, info = message.parse_info()\n",
    "        sys.stderr.write(\"Info: %s\\n\" % info)\n",
    "        clear_output(wait=True)\n",
    "    elif t == Gst.MessageType.ERROR:\n",
    "        err, debug = message.parse_error()\n",
    "        sys.stderr.write(\"Error: %s: %s\\n\" % (err, debug))\n",
    "        pipeline.set_state(Gst.State.NULL)\n",
    "        loop.quit()\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the pipeline (set to ``PLAYING`` state), create the main loop and listen to messages on the bus. Register the ``bus_call`` callback function with the ``message`` signal of the bus. Start the main loop.\n",
    "\n",
    "The video will be displayed on the monitor. The frame rate will be printed and updated below the code cell.\n",
    "\n",
    "To stop the pipeline, click the square shaped icon labelled 'Interrupt the kernel' in the top menu bar. Create a dot graph of the pipeline topology before stopping the pipeline. Quit the main loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.set_state(Gst.State.PLAYING);\n",
    "\n",
    "loop = GLib.MainLoop()\n",
    "bus = pipeline.get_bus()\n",
    "bus.add_signal_watch()\n",
    "bus.connect(\"message\", bus_call, loop)\n",
    "\n",
    "try:\n",
    "    loop.run()\n",
    "except:\n",
    "    sys.stdout.write(\"Interrupt caught\\n\")\n",
    "    pipeline.set_state(Gst.State.NULL)\n",
    "    loop.quit()\n",
    "    Gst.deinit()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook you learned how to:\n",
    "1. Create a GStreamer pipeline that demonstrates how to capture video from a V4L2 device and display it on a monitor\n",
    "2. Plot the live memory bandwidth by running the APM notebook in parallel\n",
    "3. Export the pipeline topology as a dot file image and display it in the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Copyright© 2023 AMD</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
